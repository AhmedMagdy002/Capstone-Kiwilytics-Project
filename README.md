# Capstone-Kiwilytics-Project– Daily Sales Revenue Pipeline

##  Project Objective
The goal of this project is to **automate an end-to-end data pipeline** that extracts daily sales data from a PostgreSQL database, calculates daily revenue, visualizes it as a time series plot, and schedules the entire workflow using **Apache Airflow**.

This project simulates a real-world data engineering scenario where pipelines must run automatically on a schedule, ensuring data is clean, transformed, and visualized for business use.

---

##  Pipeline Overview

### 1. **Extract**
- Pulls daily sales and order data from a PostgreSQL database using SQL.
- Saves the raw data as a CSV file.

### 2. **Data Quality Check**
- Ensures there are no missing values.
- Checks for non-positive prices or quantities.

### 3. **Transform**
- Calculates **total revenue per day** and saves the aggregated dataset.

### 4. **Visualize**
- Generates a **time series plot** of daily revenue and saves it as a PNG image.

## DAG Graph

Below is the structure of the DAG inside the Airflow UI:

<img width="931" height="134" alt="Screenshot 2025-10-04 154104" src="https://github.com/user-attachments/assets/ff2e7538-4cdd-4511-8cb3-cf77700649ec" />

##  Sample Output Plot

sample daily revenue plot generated by the pipeline:
Here’s a<img width="1200" height="600" alt="daily_revenue" src="https://github.com/user-attachments/assets/775bcc86-1d58-4df8-a635-5175b61cf422" />



## Key Takeaways

- Demonstrates how to integrate Airflow with PostgreSQL

- Automates an ETL pipeline with proper task dependencies

- Shows the use of data quality checks in production workflows

- Generates automated visualizations for daily business insights
