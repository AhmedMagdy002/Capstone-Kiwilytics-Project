# Capstone-Kiwilytics-Project– Daily Sales Revenue Pipeline

##  Project Objective
The goal of this project is to **automate an end-to-end data pipeline** that extracts daily sales data from a PostgreSQL database, calculates daily revenue, visualizes it as a time series plot, and schedules the entire workflow using **Apache Airflow**.

This project simulates a real-world data engineering scenario where pipelines must run automatically on a schedule, ensuring data is clean, transformed, and visualized for business use.

---

##  Pipeline Overview

### 1. **Extract**
- Pulls daily sales and order data from a PostgreSQL database using SQL.
- Saves the raw data as a CSV file.

### 2. **Data Quality Check**
- Ensures there are no missing values.
- Checks for non-positive prices or quantities.

### 3. **Transform**
- Calculates **total revenue per day** and saves the aggregated dataset.

### 4. **Visualize**
- Generates a **time series plot** of daily revenue and saves it as a PNG image.

## DAG Graph

Below is the structure of the DAG inside the Airflow UI:

<img width="931" height="134" alt="Screenshot 2025-10-04 154104" src="https://github.com/user-attachments/assets/ff2e7538-4cdd-4511-8cb3-cf77700649ec" />

##  Sample Output Plot

Here’s a sample daily revenue plot generated by the pipeline:

<img width="597" height="340" alt="Screenshot 2025-10-02 153003" src="https://github.com/user-attachments/assets/39d6165a-a9e1-44e2-b556-10fc5d416ed1" />

## Key Takeaways

- Demonstrates how to integrate Airflow with PostgreSQL

- Automates an ETL pipeline with proper task dependencies

- Shows the use of data quality checks in production workflows

- Generates automated visualizations for daily business insights
